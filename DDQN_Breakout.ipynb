{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import itertools\n",
        "import operator\n",
        "import copy\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.functional import crop, resize"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MNXjVvlN-6YA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4gSsz97V-6YD",
        "outputId": "6246dcdf-3089-433f-b6d5-10f51d2f0c2d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class MODEL(nn.Module):\n",
        "\n",
        "    def __init__(self, input_feature, out_feature):\n",
        "        super(MODEL, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_feature[0], out_channels=32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, out_feature)\n",
        "        )\n",
        "\n",
        "    def forward(self, x,):\n",
        "        # for layer in self.model:\n",
        "        #     x = layer(x)\n",
        "        #     print(x.size())\n",
        "        # return x\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jJz9J7GZ-6YE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [32, 32, 20, 20]           8,224\n",
            "              ReLU-2           [32, 32, 20, 20]               0\n",
            "            Conv2d-3             [32, 64, 9, 9]          32,832\n",
            "              ReLU-4             [32, 64, 9, 9]               0\n",
            "            Conv2d-5             [32, 64, 7, 7]          36,928\n",
            "              ReLU-6             [32, 64, 7, 7]               0\n",
            "           Flatten-7                 [32, 3136]               0\n",
            "            Linear-8                  [32, 512]       1,606,144\n",
            "              ReLU-9                  [32, 512]               0\n",
            "           Linear-10                    [32, 4]           2,052\n",
            "================================================================\n",
            "Total params: 1,686,180\n",
            "Trainable params: 1,686,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.45\n",
            "Forward/backward pass size (MB): 11.33\n",
            "Params size (MB): 6.43\n",
            "Estimated Total Size (MB): 21.21\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "m = MODEL((4, 84, 84), 4)\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "torchsummary.summary(m, input_size=(4, 84, 84), batch_size=32, device='cpu')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-53mkJqW-6YF",
        "outputId": "acc04190-bd80-4800-ca37-8972371d900f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "N_EPISODE = 1_000_000\n",
        "BATCH_SIZE = 64\n",
        "GAMMA = 0.99\n",
        "\n",
        "EPSILON_MIN = 0.1\n",
        "EPSILON_DECAY = 1_000_000\n",
        "\n",
        "LR = 0.00025\n",
        "\n",
        "UPDATE_MODEL = 10000\n",
        "\n",
        "CAPACITY = 1_000_000"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qgQYcfA8-6YG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "env = gym.make('Breakout-v0')\n",
        "env = gym.wrappers.GrayScaleObservation(env)\n",
        "env = gym.wrappers.FrameStack(env, 4)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jxDrt6hv-6YG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "torch.Size([4, 84, 84])"
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frame = env.reset()\n",
        "image = crop(torch.tensor(np.array(frame)), 30, 7, 180, 146)\n",
        "image = resize(image, size=[84, 84])\n",
        "image.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UOHvX12t-6YH",
        "outputId": "ffcbfabc-40ef-481f-d833-a7f3f422f9d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Agent of player\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, render=False):\n",
        "        self.n_actions = env.action_space.n\n",
        "        self.state = env.reset()\n",
        "        self.frame = crop(torch.tensor(self.state), 30, 7, 180, 146)\n",
        "        self.frame = resize(self.frame, size=[84, 84])\n",
        "        self.n_observation = self.frame.shape\n",
        "        self.policy = MODEL(self.n_observation, self.n_actions).to(device=device)\n",
        "        self.target = MODEL(self.n_observation, self.n_actions).to(device=device)\n",
        "        for p in self.target.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # self.optimizer = optim.Adam(self.net.parameters(), lr=LR,)\n",
        "        self.optimizer = optim.RMSprop(self.policy.parameters(), lr=LR, momentum=0.95)\n",
        "        # self.loss_fn = torch.nn.SmoothL1Loss()\n",
        "        self.loss_fn =  nn.MSELoss()\n",
        "        self.render = render\n",
        "        self.replay_memory = deque([], maxlen=10000)\n",
        "        self.episode_durations = []\n",
        "\n",
        "    def chooseAction(self, state, epsilon_greedy):\n",
        "        if np.random.binomial(1, epsilon_greedy) == 1:\n",
        "            return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                return torch.argmax(self.policy(state)).view(1, 1)\n",
        "\n",
        "    def play(self, episodes=50_000_000):\n",
        "        STEP = 0\n",
        "        episode_step = 0\n",
        "        # Play for number of episodes\n",
        "        for i in range(episodes):\n",
        "            current_state = env.reset()\n",
        "            # If render is True show the play\n",
        "            if self.render:\n",
        "                env.render()\n",
        "            # Transform the observed state to Tensor\n",
        "            current_state = torch.tensor(np.array(current_state), dtype=torch.float32, device=device)\n",
        "            # Crop the state\n",
        "            current_state = crop(current_state, 30, 7, 180, 146)\n",
        "            # Resize the observed frame for input model\n",
        "            current_state = resize(current_state, size=[84, 84]).unsqueeze(0)\n",
        "            # print(current_state.shape)\n",
        "            # Play each episode until get to terminate state\n",
        "            for t in itertools.count():\n",
        "                # Act\n",
        "                epsilon_greedy = EPSILON_MIN + max(EPSILON_DECAY - STEP, 0) / EPSILON_DECAY * (1 - EPSILON_MIN)\n",
        "                action = self.chooseAction(current_state, epsilon_greedy)\n",
        "                # Perform Act\n",
        "                next_state, reward, terminated, truncated = env.step(action.item())\n",
        "                if self.render:\n",
        "                    env.render()\n",
        "                # done = terminated or truncated\n",
        "                if terminated:\n",
        "                    next_state = None\n",
        "                else:\n",
        "                    next_state = torch.tensor(next_state, dtype=torch.float32, device=device)\n",
        "                    next_state = crop(next_state, 30, 7, 180, 146)\n",
        "                    next_state = resize(next_state, size=[84, 84]).unsqueeze(0)\n",
        "\n",
        "                reward = torch.tensor(reward, device=device).unsqueeze(0)\n",
        "                reward = torch.clip(reward, -1, 1)\n",
        "                # Remember\n",
        "                self.replay_memory.append((current_state, action, reward, next_state))\n",
        "\n",
        "                # Update Second Model\n",
        "                if STEP % UPDATE_MODEL == 0:\n",
        "                    self.target.load_state_dict(self.policy.state_dict())\n",
        "                # Learn\n",
        "                if len(self.replay_memory) > BATCH_SIZE * 10:\n",
        "                    # Sample From Memory\n",
        "                    minibatch = random.sample(self.replay_memory, BATCH_SIZE)\n",
        "\n",
        "                    curr_state_batch = torch.cat(tuple(map(operator.itemgetter(0), minibatch )))\n",
        "                    action_batch = torch.cat(tuple(map(operator.itemgetter(1), minibatch )))\n",
        "                    reward_batch = torch.cat(tuple(map(operator.itemgetter(2), minibatch )))\n",
        "                    next_state_batch = tuple(map(operator.itemgetter(3), minibatch ))\n",
        "                    # Here if we don\n",
        "                    mask_next_state = []\n",
        "                    not_none_next_state = []\n",
        "                    for state in next_state_batch:\n",
        "                        if state is not None:\n",
        "                            mask_next_state.append(True)\n",
        "                            not_none_next_state.append(state)\n",
        "                        else:\n",
        "                            mask_next_state.append(False)\n",
        "\n",
        "                    mask_next_state = torch.tensor(mask_next_state, device=device)\n",
        "                    not_none_next_state = torch.cat(not_none_next_state)\n",
        "\n",
        "                    # Get TD Estimate\n",
        "                    estimation = self.policy(curr_state_batch).gather(1, action_batch)\n",
        "                    # Get TD Target\n",
        "                    with torch.no_grad():\n",
        "                        # The state value for next state\n",
        "                        next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "                        # Selecting best action for next state with online model\n",
        "                        next_state_estimation= self.policy(not_none_next_state)\n",
        "                        select_action = torch.argmax(next_state_estimation, dim=1).unsqueeze(1)\n",
        "                        # With best action compute state value for next state using target network\n",
        "                        next_state_q_values = self.target(not_none_next_state).gather(1, select_action).squeeze(1)\n",
        "                        next_state_values[mask_next_state] = next_state_q_values\n",
        "                        # Calculate target estimation\n",
        "                        target_value = (reward_batch + (GAMMA * next_state_values)).unsqueeze(1)\n",
        "\n",
        "                    # Backpropagation loss through Q_online\n",
        "                    loss = self.loss_fn(estimation, target_value)\n",
        "                    self.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                STEP += 1\n",
        "                episode_step += 1\n",
        "\n",
        "                current_state = next_state\n",
        "\n",
        "                if terminated:\n",
        "                    self.episode_durations.append(episode_step + 1)\n",
        "                    episode_step = 0\n",
        "                    break\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nHM4XDi5-6YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ag = Agent(render=True)\n",
        "ag.play(N_EPISODE)"
      ],
      "metadata": {
        "id": "jTDYam7--8zN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}